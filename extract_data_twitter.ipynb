{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /home/kan/miniconda3/envs/pydml/lib/python3.8/site-packages (4.8.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /home/kan/miniconda3/envs/pydml/lib/python3.8/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /home/kan/miniconda3/envs/pydml/lib/python3.8/site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /home/kan/miniconda3/envs/pydml/lib/python3.8/site-packages (from tweepy) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/kan/miniconda3/envs/pydml/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kan/miniconda3/envs/pydml/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/kan/miniconda3/envs/pydml/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kan/miniconda3/envs/pydml/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 724 seconds.\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "import tweepy\n",
    "import json\n",
    "import time\n",
    "client = tweepy.Client(bearer_token=\"AAAAAAAAAAAAAAAAAAAAABoebgEAAAAA8nOwpOH6GviG0pVFbGAEowC6lrE%3DvQmBGiPwQ2EJKcoMQUNYDwgb0d5vkjxvSPtkuqY0FFGY9D2yS8\", wait_on_rate_limit=True)\n",
    "\n",
    "\n",
    "    \n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from itertools import chain\n",
    "import math\n",
    "import numpy as np\n",
    "file = \"test.data.txt\"\n",
    "file_open = open('./project-data/' + file, 'r')\n",
    "count = 0\n",
    "delta = pd.DataFrame()\n",
    "for line in file_open.readlines():\n",
    "    tweet_data={}\n",
    "    line = line.strip()\n",
    "    each_tweet = line.split(',')\n",
    "    main_tweet_id = each_tweet[0]\n",
    "    main_tweet = client.get_tweet(main_tweet_id,expansions=\"author_id\",user_fields=[\"verified\",\"public_metrics\"])\n",
    "    each_tweet = each_tweet[1:]\n",
    "    # count+=len(each_tweet)\n",
    "    if len(each_tweet) > 100:\n",
    "        num_sub_list = math.ceil(len(each_tweet)/100)\n",
    "        a = np.array_split(each_tweet, num_sub_list)\n",
    "        tweets = []\n",
    "        for sub_list in a:\n",
    "            sub_list = sub_list.tolist()\n",
    "            tw = client.get_tweets(sub_list, tweet_fields=[\"created_at\"], expansions=\"author_id\",user_fields=[\"verified\",\"public_metrics\"])\n",
    "            tweets.append(tw.data)\n",
    "        \n",
    "        tweets =  list(chain.from_iterable(tweets))\n",
    "\n",
    "        # tweets = client.get_tweets()\n",
    "    elif len(each_tweet) <= 100 and len(each_tweet) > 0:\n",
    "        tweets = client.get_tweets(each_tweet,tweet_fields=[\"created_at\"],expansions=\"author_id\", user_fields=[\"verified\",\"public_metrics\"])\n",
    " \n",
    "        tweets = tweets.data if tweets.data is not None else []\n",
    "    replies = []\n",
    "    if len(tweets) > 0:\n",
    "        for tweet in tweets:\n",
    "            reply_data = {}\n",
    "            reply_data['tweet_id'] = tweet.id\n",
    "            reply_data['tweet'] = tweet.text\n",
    "            reply_data['created_at'] = tweet.created_at.timestamp()\n",
    "\n",
    "            replies.append(reply_data)\n",
    "\n",
    "    if main_tweet.data is not None:\n",
    "        tweet_data['main_tweet'] = main_tweet.data.text\n",
    "        tweet_data['main_tweet_id'] = main_tweet.data.id\n",
    "        tweet_data['verified'] = main_tweet.includes[\"users\"][0].verified\n",
    "        tweet_data['followers'] = main_tweet.includes[\"users\"][0].public_metrics['followers_count']\n",
    "\n",
    "    else:\n",
    "        tweet_data['main_tweet'] = \"\"\n",
    "        tweet_data['main_tweet_id'] = main_tweet_id\n",
    "        tweet_data['verified'] = False\n",
    "        tweet_data['followers'] = 0\n",
    "    tweet_data['replies'] = json.dumps(replies) \n",
    "    \n",
    "    delta = delta.append(pd.DataFrame([tweet_data]))\n",
    "    delta.to_csv('./project-data/%s.csv'%file, index=False)\n",
    " \n",
    "    \n",
    "\n",
    "file_open.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta = pd.read_csv('./project-data/%s.csv'%file,keep_default_na=False)\n",
    "# label = open('./project-data/dev.label.txt', 'r')\n",
    "# label_data = label.readlines()\n",
    "# delta\n",
    "# delta = delta.iloc[:, 1:]\n",
    "\n",
    "\n",
    "# label_data = [x.strip() for x in label_data]\n",
    "delta[\"main_tweet\"] = delta[\"main_tweet\"].astype(str)\n",
    "delta['main_tweet'].replace('nan', '', inplace=True)\n",
    "# delta['label'] = label_data\n",
    "\n",
    "delta.to_csv('./project-data/%s.csv'%file, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cdb69ebf63b127ccdd1f4d2b9e6e004bc1933417c744d4c5778c2e874cc47f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pydml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
